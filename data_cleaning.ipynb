{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa5ab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this notebook, we clean the SBAnational dataset, \\n## to allow for easier data exploration and analysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"In this notebook, we clean the SBAnational dataset, \n",
    "## to allow for easier data exploration and analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ee9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b285312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899164, 27)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 899164 entries, 0 to 899163\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   LoanNr_ChkDgt      899164 non-null  int64         \n",
      " 1   Name               899150 non-null  object        \n",
      " 2   City               899134 non-null  object        \n",
      " 3   State              899150 non-null  object        \n",
      " 4   Zip                899164 non-null  int64         \n",
      " 5   Bank               897605 non-null  object        \n",
      " 6   BankState          897598 non-null  object        \n",
      " 7   NAICS              899164 non-null  int64         \n",
      " 8   ApprovalDate       899164 non-null  datetime64[ns]\n",
      " 9   ApprovalFY         899164 non-null  object        \n",
      " 10  Term               899164 non-null  int64         \n",
      " 11  NoEmp              899164 non-null  int64         \n",
      " 12  NewExist           899028 non-null  float64       \n",
      " 13  CreateJob          899164 non-null  int64         \n",
      " 14  RetainedJob        899164 non-null  int64         \n",
      " 15  FranchiseCode      899164 non-null  int64         \n",
      " 16  UrbanRural         899164 non-null  int64         \n",
      " 17  RevLineCr          894636 non-null  object        \n",
      " 18  LowDoc             896582 non-null  object        \n",
      " 19  ChgOffDate         162699 non-null  object        \n",
      " 20  DisbursementDate   896796 non-null  datetime64[ns]\n",
      " 21  DisbursementGross  899164 non-null  object        \n",
      " 22  BalanceGross       899164 non-null  object        \n",
      " 23  MIS_Status         897167 non-null  object        \n",
      " 24  ChgOffPrinGr       899164 non-null  object        \n",
      " 25  GrAppv             899164 non-null  object        \n",
      " 26  SBA_Appv           899164 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(9), object(15)\n",
      "memory usage: 185.2+ MB\n",
      "None\n",
      "   LoanNr_ChkDgt                           Name          City State    Zip  \\\n",
      "0     1000014003                 ABC HOBBYCRAFT    EVANSVILLE    IN  47711   \n",
      "1     1000024006    LANDMARK BAR & GRILLE (THE)     NEW PARIS    IN  46526   \n",
      "2     1000034009          WHITLOCK DDS, TODD M.   BLOOMINGTON    IN  47401   \n",
      "3     1000044001  BIG BUCKS PAWN & JEWELRY, LLC  BROKEN ARROW    OK  74012   \n",
      "4     1000054004    ANASTASIA CONFECTIONS, INC.       ORLANDO    FL  32801   \n",
      "\n",
      "                            Bank BankState   NAICS ApprovalDate ApprovalFY  \\\n",
      "0               FIFTH THIRD BANK        OH  451120   1997-02-28       1997   \n",
      "1                1ST SOURCE BANK        IN  722410   1997-02-28       1997   \n",
      "2        GRANT COUNTY STATE BANK        IN  621210   1997-02-28       1997   \n",
      "3  1ST NATL BK & TR CO OF BROKEN        OK       0   1997-02-28       1997   \n",
      "4        FLORIDA BUS. DEVEL CORP        FL       0   1997-02-28       1997   \n",
      "\n",
      "   ...  RevLineCr  LowDoc  ChgOffDate  DisbursementDate  DisbursementGross  \\\n",
      "0  ...          N       Y         NaN        1999-02-28        $60,000.00    \n",
      "1  ...          N       Y         NaN        1997-05-31        $40,000.00    \n",
      "2  ...          N       N         NaN        1997-12-31       $287,000.00    \n",
      "3  ...          N       Y         NaN        1997-06-30        $35,000.00    \n",
      "4  ...          N       N         NaN        1997-05-14       $229,000.00    \n",
      "\n",
      "   BalanceGross  MIS_Status ChgOffPrinGr        GrAppv      SBA_Appv  \n",
      "0        $0.00        P I F       $0.00    $60,000.00    $48,000.00   \n",
      "1        $0.00        P I F       $0.00    $40,000.00    $32,000.00   \n",
      "2        $0.00        P I F       $0.00   $287,000.00   $215,250.00   \n",
      "3        $0.00        P I F       $0.00    $35,000.00    $28,000.00   \n",
      "4        $0.00        P I F       $0.00   $229,000.00   $229,000.00   \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"SBAnational.csv\", dtype={'ApprovalFY': str, 'ApprovalDate': str, 'DisbursementDate': str},\n",
    "                 parse_dates=['ApprovalDate', 'DisbursementDate'])\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657482ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "df[df.duplicated(['LoanNr_ChkDgt'])]\n",
    "# There are no duplicate rows\n",
    "\n",
    "# Checking for empty rows\n",
    "print(df.isnull().all(axis=1).sum())\n",
    "# There are no empty rows\n",
    "\n",
    "# Checking for empty columns\n",
    "print(df.isnull().all(axis=0).sum())\n",
    "# There are no empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628759a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoanNr_ChkDgt             0\n",
      "Name                     14\n",
      "City                     30\n",
      "State                    14\n",
      "Zip                       0\n",
      "Bank                   1559\n",
      "BankState              1566\n",
      "NAICS                     0\n",
      "ApprovalDate              0\n",
      "ApprovalFY                0\n",
      "Term                      0\n",
      "NoEmp                     0\n",
      "NewExist                136\n",
      "CreateJob                 0\n",
      "RetainedJob               0\n",
      "FranchiseCode             0\n",
      "UrbanRural                0\n",
      "RevLineCr              4528\n",
      "LowDoc                 2582\n",
      "ChgOffDate           736465\n",
      "DisbursementDate       2368\n",
      "DisbursementGross         0\n",
      "BalanceGross              0\n",
      "MIS_Status             1997\n",
      "ChgOffPrinGr              0\n",
      "GrAppv                    0\n",
      "SBA_Appv                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values in columns\n",
    "print(df.isnull().sum())\n",
    "# We will now investigate/correct these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73da680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8190552557709161\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the rate of nulls in ChgOffDate column\n",
    "print(df.ChgOffDate.isnull().sum() / (df.ChgOffDate.notnull().sum() + df.ChgOffDate.isnull().sum()))\n",
    "# As ~80% of the values of the column are null, we discard it\n",
    "df.drop('ChgOffDate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964e2691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NewExist  LoanNr_ChkDgt\n",
      "0       0.0           1034\n",
      "1       1.0         644869\n",
      "2       2.0         253125\n"
     ]
    }
   ],
   "source": [
    "# Investigating NewExist\n",
    "print(df.groupby('NewExist').LoanNr_ChkDgt.count().reset_index())\n",
    "\n",
    "# Everything is fine; simply replace null values in NewExist with 0, where 0 = 'Unknown'\n",
    "df['NewExist'].fillna(0, inplace=True)\n",
    "\n",
    "# As there are a small amount of unknown rows, we drop them altogether. Also, for uniformity with other\n",
    "# variables, we map 2 -> 1 and 1 -> 0\n",
    "df.drop(df[df.NewExist < 0.5].index, inplace=True)\n",
    "df.NewExist = df.NewExist.apply(lambda x: x - 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044c2bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RevLineCr  LoanNr_ChkDgt\n",
      "0          ,              1\n",
      "1          -              1\n",
      "2          .              1\n",
      "3          0         257546\n",
      "4          1             22\n",
      "5          2              6\n",
      "6          3              1\n",
      "7          4              1\n",
      "8          5              1\n",
      "9          7              1\n",
      "10         A              1\n",
      "11         C              2\n",
      "12         N         419258\n",
      "13         Q              1\n",
      "14         R             14\n",
      "15         T          15277\n",
      "16         Y         201324\n",
      "17         `             11\n"
     ]
    }
   ],
   "source": [
    "# Investigating RevLineCr\n",
    "print(df.groupby('RevLineCr').LoanNr_ChkDgt.count().reset_index())\n",
    "\n",
    "# 0, Y, N dominate - replace other values with 0, where 0 = 'Unknown'\n",
    "df.RevLineCr.fillna(0, inplace=True)\n",
    "df.loc[~df.RevLineCr.isin(['Y', 'N']), 'RevLineCr'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd341bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LowDoc  LoanNr_ChkDgt\n",
      "0      0           1490\n",
      "1      1              1\n",
      "2      A            497\n",
      "3      C            754\n",
      "4      N         781786\n",
      "5      R             75\n",
      "6      S            602\n",
      "7      Y         110210\n"
     ]
    }
   ],
   "source": [
    "# Investigating LowDoc\n",
    "print(df.groupby('LowDoc').LoanNr_ChkDgt.count().reset_index())\n",
    "\n",
    "# Similarly to above, we change the values that aren't Y or N to 0, where 0 = Unknown\n",
    "df.LowDoc.fillna(0, inplace=True)\n",
    "df.loc[~df.LowDoc.isin(['Y', 'N']), 'LowDoc'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9ab312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MIS_Status  LoanNr_ChkDgt\n",
      "0     CHGOFF         157481\n",
      "1      P I F         738524\n"
     ]
    }
   ],
   "source": [
    "# Investigating MIS_Status\n",
    "print(df.groupby('MIS_Status').LoanNr_ChkDgt.count().reset_index())\n",
    "\n",
    "# There are no surprising values here. Our analysis relies on MIS_Status being non-null,\n",
    "# so we drop all rows that are null in this column\n",
    "df = df.dropna(subset='MIS_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea84849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill name nulls with Unknown\n",
    "df.Name.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863856a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511\n",
      "145106               KOREA EXCHANGE BANK\n",
      "424311    STANDARD CHARTERED BK KOREA LT\n",
      "444679      HONGKONG & SHANGHAI BK. CORP\n",
      "447971    STANDARD CHARTERED BK KOREA LT\n",
      "674674      HONGKONG & SHANGHAI BK. CORP\n",
      "793950    THE BANK OF EAST ASIA, LIMITED\n",
      "859233    THE BANK OF EAST ASIA, LIMITED\n",
      "Name: Bank, dtype: object\n",
      "      BankState  LoanNr_ChkDgt\n",
      "0            AK           1434\n",
      "1            AL          12118\n",
      "2            AN              1\n",
      "3            AR           6297\n",
      "4            AZ           3952\n",
      "5            CA         117933\n",
      "6            CO          10561\n",
      "7            CT           9880\n",
      "8            DC           3995\n",
      "9            DE          24498\n",
      "10           EN              1\n",
      "11           FL          13793\n",
      "12           GA          13789\n",
      "13           GU              4\n",
      "14           HI           2981\n",
      "15           IA           9849\n",
      "16           ID           4310\n",
      "17           IL          65805\n",
      "18           IN           7612\n",
      "19           KS           8856\n",
      "20           KY           4365\n",
      "21           LA           5055\n",
      "22           MA          13818\n",
      "23           MD           6977\n",
      "24           ME           3685\n",
      "25           MI           7348\n",
      "26           MN          19929\n",
      "27           MO          14811\n",
      "28           MS           5910\n",
      "29           MT           7838\n",
      "30           NC          79405\n",
      "31           ND           5100\n",
      "32           NE           5320\n",
      "33           NH           6786\n",
      "34           NJ           9405\n",
      "35           NM           4414\n",
      "36           NV           4303\n",
      "37           NY          39480\n",
      "38           OH          58362\n",
      "39           OK           7308\n",
      "40           OR          11360\n",
      "41  Outside_USA              7\n",
      "42           PA          16911\n",
      "43           PR            155\n",
      "44           RI          44085\n",
      "45           SC           7454\n",
      "46           SD          51022\n",
      "47           TN           5614\n",
      "48           TX          47712\n",
      "49           UN           1504\n",
      "50           UT          18980\n",
      "51           VA          28941\n",
      "52           VI              1\n",
      "53           VT           4745\n",
      "54           WA          10669\n",
      "55           WI          15391\n",
      "56           WV           2003\n",
      "57           WY           2163\n"
     ]
    }
   ],
   "source": [
    "# Checking the relationship between null values in Bank and BankState\n",
    "temp1 = df[(df['Bank'].isnull() | df['BankState'].isnull())]\n",
    "print(len(temp1))\n",
    "\n",
    "# BankState being null implies Bank is null. Let's examine rows where BankState is null but Bank isn't.\n",
    "temp2 = df[(df['Bank'].notnull() & df['BankState'].isnull())]\n",
    "print(temp2['Bank'])\n",
    "\n",
    "# These are foreign banks; let's replace these nulls with 'Outside_USA', fill the rest with 'Unknown' / 'UN'\n",
    "df.loc[(df['Bank'].notnull() & df['BankState'].isnull()), 'BankState'] = 'Outside_USA'\n",
    "df.Bank.fillna('Unknown', inplace=True)\n",
    "df.BankState.fillna('UN', inplace=True)\n",
    "\n",
    "# Rechecking Bank\n",
    "print(df.groupby('BankState').LoanNr_ChkDgt.count().reset_index())\n",
    "# In fact, for our later analysis it's best to class all non-US states as 'UN'\n",
    "state_abbrev_ls = [ 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
    "df.loc[~df.BankState.isin(state_abbrev_ls), 'BankState'] = 'UN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4db9252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Similarly, let's examine where State and City are unknown, and see if we can fill the gaps\n",
    "print(len(df[(df['City'].isnull() & df['State'].isnull())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fa2c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264664               CAMERON PARK\n",
      "306274           BOX 267, APO  AP\n",
      "328526                    WICHITA\n",
      "351072    1542,TABUK,SAUDI ARABIA\n",
      "366139         PALM BEACH GARDENS\n",
      "366158                      CASCO\n",
      "367007                   SOMERSET\n",
      "379174             SALT LAKE CITY\n",
      "385418                 LAKE OZARK\n",
      "869948                 A452638533\n",
      "871847                 A452638533\n",
      "885335                 A452638533\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# These sets are disjoint - however, given the city, we could fill in the state:\n",
    "print(df[(df['City'].notnull() & df.State.isnull())]['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a983b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869948    A452638533\n",
      "871847    A452638533\n",
      "885335    A452638533\n",
      "Name: City, dtype: object\n",
      "306274    BOX 267, APO  AP\n",
      "Name: City, dtype: object\n",
      "22211              CASCO\n",
      "131394             CASCO\n",
      "159316       SOUTH CASCO\n",
      "301335       SOUTH CASCO\n",
      "324947       SOUTH CASCO\n",
      "349249             CASCO\n",
      "366158             CASCO\n",
      "514509       SOUTH CASCO\n",
      "529930             CASCO\n",
      "646547             CASCO\n",
      "664110             CASCO\n",
      "701499             CASCO\n",
      "748728             CASCO\n",
      "750701             CASCO\n",
      "775304             CASCO\n",
      "779109             CASCO\n",
      "859154             CASCO\n",
      "872787    CASCO TOWNSHIP\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Investigating these potential values\n",
    "print(df[(df[\"City\"].str.startswith('A4', na=False))]['City'])  # These values are erroneous\n",
    "print(df[(df.City.str.contains('BOX 267', na=False))]['City'])  # This value is erroneous\n",
    "print(df[(df.City.str.contains('CASCO', na=False))]['City'])  # We cannot deduce the state of 'CASCO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b9a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace the A4... entries and the 'BOX 267' entry with nulls, and fill in states that we know.\n",
    "df.loc[df.City.str.startswith('A4', na=False), 'City'] = None\n",
    "df.loc[df.City.str.contains('BOX 267', na=False), 'City'] = None\n",
    "key_ls = df[(df['City'].notnull() & df.State.isnull())]['LoanNr_ChkDgt'].tolist()\n",
    "state_ls = ['NJ', 'NY', 'CA', 'KS', None, 'FL', None, 'NJ', 'UT', 'MO']\n",
    "for i in range(len(key_ls)):\n",
    "    df.loc[df.LoanNr_ChkDgt == key_ls[i], 'State'] = state_ls[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eea1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we convert the remaining nulls to 'Unknown' / 'U'\n",
    "df.City.fillna('Unknown', inplace=True)\n",
    "df.State.fillna('U', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad169679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting currency datatypes to floats to make calculations easier\n",
    "currency_cols = ['DisbursementGross', 'BalanceGross', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv']\n",
    "for column in currency_cols:\n",
    "    df[column] = df[column].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd57f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699732    1976A\n",
      "704030    1976A\n",
      "705375    1976A\n",
      "710381    1976A\n",
      "713245    1976A\n",
      "748029    1976A\n",
      "751519    1976A\n",
      "769515    1976A\n",
      "775002    1976A\n",
      "775430    1976A\n",
      "775978    1976A\n",
      "776367    1976A\n",
      "780120    1976A\n",
      "781090    1976A\n",
      "784351    1976A\n",
      "788539    1976A\n",
      "788661    1976A\n",
      "793733    1976A\n",
      "Name: ApprovalFY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting ApprovalFY years to int; however, these is an issue...\n",
    "print(df.loc[df.ApprovalFY.str.contains('\\D')].ApprovalFY)\n",
    "\n",
    "# The letter 'A' erroneously appears in some years - let's remove them\n",
    "df.ApprovalFY = df.ApprovalFY.replace('A', '', regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dc998ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.to_csv('SBAnational_cleaned.csv', index=False)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning done; saving as csv to import later\n",
    "\"\"\"df.to_csv('SBAnational_cleaned.csv', index=False)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
